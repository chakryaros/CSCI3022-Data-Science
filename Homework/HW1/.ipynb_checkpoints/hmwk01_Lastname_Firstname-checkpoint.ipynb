{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**: Chakrya Ros\n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **5 PM on Friday February 1**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available under the **Data** module on Canvas. To make life easier on the graders if they need to run your code, do not change the relative path names here. Instead, move the files around on your computer.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Kernel $\\rightarrow$ Restart & Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | [Problem 4](#p4) | [Problem 5](#p5)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p1'></a>\n",
    "\n",
    "### (10 pts) Problem 1 \n",
    "***\n",
    "\n",
    "![hedgehog](https://www.irishexaminer.com/remote/media.central.ie/media/images/h/hedgehog17_large.jpg?width=648&s=ie-467290)\n",
    "\n",
    "Hedgehogs are undeniably one of the cutest creatures in all of the land, so the University of Colorado Boulder wants to switch its mascot to the hedgehog. Before making the switch, the CU officials need to know whether they will be able to find new hedgehog mascot handlers, similar to the current Ralphie handlers. You are called upon to perform an experiment to order to determine how fit CU Boulder students are for hedgehog-handling. There are too many students at CU for you to test all of their **Hedgehog-Handling Ability** (HHA), so from a roster of all students and their majors, you will randomly test the HHA of one-tenth of the majors from each department on campus. (Assume nobody is a double major, and assume that everybody has a major.) From this sample, you will estimate the mean HHA of all students on campus, and let the CU officials know whether or not CU students will be able to handle hedgehogs.\n",
    "\n",
    "Identify the following: \n",
    "\n",
    "- the population : CU Boulder Student\n",
    "- the sample frame : roster\n",
    "- the sample : mean\n",
    "- the type of sample : stratified sample\n",
    "- the quantity of interest : Hedgehog-Handling Ability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p2'></a>\n",
    "\n",
    "### (20 pts) Problem 2 \n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and the sample median to extreme outliers and changes in the dataset is to replace one or more elements in a given dataset by a number $y$ and investigate the eﬀect when $y$ changes. To illustrate this, consider the dataset\n",
    "\n",
    "$$\n",
    "y \\quad \n",
    "5.4 \\quad\n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7 \\quad\n",
    "6.0 \\quad\n",
    "1.9\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Compute the sample mean and sample median for $y=2$. Compute them both again for $y=8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate sample mean\n",
    "\n",
    "if y = 2\n",
    "\n",
    "    mean = (−4.5+5.4+5.0+6.5+7.7+6.0+1.9)/7 = 4.928 \n",
    "if y = 8\n",
    "\n",
    "    mean = (−4.5+5.4+5.0+6.5+7.7+6.0+1.9)/7 = 5.786 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate sample median\n",
    "\n",
    "if y = 2\n",
    "\n",
    "    list = [1.9, 2, 5.0, 5.4, 6.0, 6.5, 7.7]\n",
    "    \n",
    "    median = 5.4\n",
    "    \n",
    "if y = 8\n",
    "\n",
    "    list = [1.9, 5.0, 5.4, 6.0, 6.5, 7.7, 8]\n",
    "    \n",
    "    median = 6.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Is there a value for $y$ that would make the mean of those data equal to $4$? If so, calculate the value of $y$ that makes the mean equal to $4$. If not, clearly explain why not.\n",
    "\n",
    "yes, there is a value for y = $-4.5$ that make the mean of those data equal to $4$.\n",
    "mean = $(-4.5 + 5.4 + 5.0 + 6.5 + 7.7 + 6.0 + 1.9)/7 = 4$\n",
    "\n",
    "Is there a value for $y$ that would make the median of those data equal to $4$? If so, calculate the value of $y$ that makes the median equal to $4$. If not, clearly explain why not.\n",
    "\n",
    "No, because we just sort the list and choose the midpoint of the list and in list, the other six elements don't contain $4$ value. In this case, there is no $y$ value that make the median of those data equal to $4$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of list_:  4.0\n"
     ]
    }
   ],
   "source": [
    "#y = -4.5 that make the mean of those data equal to 4\n",
    "list_ = [-4.5, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "def meanOfData(list_):\n",
    "    num_len = len(list_)\n",
    "    sum_ = sum(list_)\n",
    "    mean_ = sum_/num_len\n",
    "    return mean_\n",
    "print(\"Mean of list_: \", meanOfData(list_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the sample median for the following cases: \n",
    "- $y=5$ \n",
    "- $y=50$ \n",
    "- $y=5.39$ \n",
    "- $y=5.41$\n",
    "- $y \\to \\infty$ \n",
    "- $y \\to -\\infty$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of y = 5:  5.4\n",
      "Median of y = 50:  6.0\n",
      "Median of y = 5.39:  5.4\n",
      "Median of y = 5.41:  5.41\n",
      "Median of y = infty:  6.0\n"
     ]
    }
   ],
   "source": [
    "pos_inf = float(\"inf\")\n",
    "neg_inf = float(\"inf\")\n",
    "y_5 = [5, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "y_50 = [50, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "y_539 = [5.39, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "y_541 = [5.41, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "y_inf = [pos_inf, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "N_inf = [neg_inf, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "def medianOfData(list_):\n",
    "    num_len = len(list_)\n",
    "    list_.sort()\n",
    "    median_ = 0\n",
    "    if num_len % 2 == 0:\n",
    "        m1 = list_[num_len//2]\n",
    "        m2 = list_[num_len//2 - 1]\n",
    "        median_ = (m1+m2)/2\n",
    "    else:\n",
    "        median_ = list_[num_len//2]\n",
    "    return median_\n",
    "print(\"Median of y = 5: \", medianOfData(y_5))\n",
    "print(\"Median of y = 50: \", medianOfData(y_50))\n",
    "print(\"Median of y = 5.39: \", medianOfData(y_539))\n",
    "print(\"Median of y = 5.41: \", medianOfData(y_541))\n",
    "print(\"Median of y = infty: \", medianOfData(y_inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Think about the previous parts, above, and describe in words or mathematical notation the answers to the following two questions:\n",
    "\n",
    "- By varying $y$, what is the set of all the possible values that the sample mean could take on?\n",
    "- By varying $y$, what is the set of all the possible values that the sample median could take on? Specifically, for what sets of $y$ values does the median take on its different possible values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The set of all the possible values that the sample mean could take on is all real number expect positive and negative infinity.\n",
    "- The set of all the possible values that the sample median cound take on is {4.4, 6.0, 5.41 }\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p3'></a>\n",
    "\n",
    "### (20 pts) Problem 3 \n",
    "***\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2 \\qquad \\tag{Equation 1}\n",
    "$$\n",
    "\n",
    "where here the subscript $n$'s indicate the number of observations in the sample. Notice that a natural computation of the variance requires two passes over the data: one to compute the mean, and a second to subtract the mean from each observation and compute the sum of squares. It is often useful to be able to compute the variance in a single pass, inspecting each value $x_k$ only once; for example, when the data are being collected without enough storage to keep all the values, or when costs of memory access dominate those of computation. In this problem you will explore two methods for such an _online_ computation of the mean.  \n",
    "\n",
    "**Part A**: Show algebraically that the following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$\n",
    "\n",
    "Note that you can get an expression for $\\bar{x}_{n-1}$ by simply replacing $n$ in Equation 1 above with $n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace n in Equation 1 with n - 1, we get\n",
    "\n",
    "$$\n",
    " \\bar{x}_{n-1} = \\frac{1}{n-1}\\sum_{k=1}^n x_k \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Write a function `my_sample_mean` that takes as its input a numpy array and returns the mean of that numpy array using the formulas from class (written above). Write another function `my_sample_var` that takes as its input a numpy array and returns the variance of that numpy array, again using the formulas from class (written above). You may **not** use any built-in sample mean or variance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_mean(list_):\n",
    "    arr = np.array(list_) #get numpy of array\n",
    "    arr_Len= np.size(arr) #get the size of array\n",
    "    sum_ = np.sum(arr)    #sum of element in array\n",
    "    mean_ = sum_/arr_Len\n",
    "    return mean_\n",
    "\n",
    "#li = [2.0, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "#print(\"sample mean:\",my_sample_mean(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_var(list_):\n",
    "    arr = np.array(list_)\n",
    "    arr_Len = np.size(arr) #size of numpy array\n",
    "    sum_ = np.sum(arr)\n",
    "    mean_ = sum_/arr_Len #calculate mean\n",
    "    var = 0.0\n",
    "    d =0.0\n",
    "    for i in np.nditer(arr):\n",
    "        d = d + ((i - mean_) **2) #calculate the differnce between each element and mean and sum\n",
    "    var = d/(arr_Len)  #calculate sample variance\n",
    "    return var\n",
    "#li = [2.0, 5.4, 5.0, 6.5, 7.7, 6.0, 1.9]\n",
    "#print(\"sample variance:\",my_sample_var(li))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use your functions from Part B to compute the sample mean and sample variance of the following array, which contains the hedgehog-handling abilities (HHA) of a sample of 12 CU Boulder hedgehog handlers.\n",
    "\n",
    "`hha = [98, 26, 83, 56, 60, 39, 81, 19, 72, 78, 94, 42]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean that contains HHA: 62.333333333333336\n",
      "Sample variance that contains HHA: 632.5555555555555\n"
     ]
    }
   ],
   "source": [
    "hha = [98, 26, 83, 56, 60, 39, 81, 19, 72, 78, 94, 42]\n",
    "sample_mean = my_sample_mean(hha)\n",
    "print(\"Sample mean that contains HHA:\", sample_mean)\n",
    "sample_var = my_sample_var(hha)\n",
    "print(\"Sample variance that contains HHA:\", sample_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Implement a third function called `update_mean` that implements the formula whose validity you proved in Part A. Note that this function will need to take as its input three things: $x_n$, $\\bar{x}_{n-1}$ and $n$. A function header is provided for you. This function may be auto-graded, so please do not change the given API - the order of inputs matters! If you change it, you might lose points.\n",
    "\n",
    "Use this function to compute the values that you get from taking the mean of the first hedgehog handler, the first two hedgehog handlers, the first three hedgehog handlers, and so on up to all of the hedgehog handler data points. Store your HHA means in a numpy array called `hha_means`.  Report all 12 estimates in `hha_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given API:\n",
    "def update_mean(prev_mean, xn, n):\n",
    "    update_m = prev_mean + (xn-prev_mean)/n\n",
    "   # hha_means = np.append(update_m)\n",
    "    return update_m     #the updated mean\n",
    "#print(update_mean(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure your function complies with the given API, run this small test, where we suppose we have a mean of $\\bar{x}_n = 1$ with the first $2$ data points (`prev_mean`), and we update this with the 3rd ($n=3$) data point which is $x_3=2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert update_mean(1,2,3)==4/3, \"Warning: function seems broken.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p4'></a>\n",
    "\n",
    "### (25 pts) Problem 4\n",
    "*** \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "We have the data on survival rates by class and by sex, so let's figure out whether there is evidence for these scenarios. Access the Titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival (**Survived**), and gender (**Sex**) of passengers, among other things. Be sure to use the `titanic_data.csv` data set, *not* the `clean_titanic_data` file from the in-class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/chakryaros/Dropbox/csci3022_DataSci/HW1/titanic_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours instead. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the class warfare occured in the final hours abooard the Titanic, I might expect the frist class people would be more survived. If the male chivalry was widespread during the final hours instead, I might expext that women were more survived. Yes, these two hypotheses are not exlusive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use Pandas methods to create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. Be sure to show any exploratory work determining if/where there are rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 888\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    714 non-null int64\n",
      "Survived       714 non-null int64\n",
      "Pclass         714 non-null int64\n",
      "Name           714 non-null object\n",
      "Sex            714 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          714 non-null int64\n",
      "Parch          714 non-null int64\n",
      "Ticket         714 non-null object\n",
      "Fare           714 non-null float64\n",
      "Cabin          165 non-null object\n",
      "Embarked       713 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 72.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#create a clean data set by removing any rows from the DataFrame that are missing value\n",
    "dfTitanic = df.dropna(subset=['Survived', 'Pclass', 'Age', 'Sex']).copy()\n",
    "dfTitanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the fraction of survivors according to class and gender. There are 3 passenger classes and 2 sexes in the data set, so you should report all 6 possible combinations.  Then, answer 3 questions:\n",
    "* **(i)** Within each passenger class, were men or women more/less/equally likely to survive?\n",
    "* **(ii)**  Looking at only the male or only the female passengers, how is passenger class related to the category's survival rate?\n",
    "* **(iii)**  Did men in first class or women in third class have a higher survival rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women survived in first class: 72\n",
      "Men survived in first class: 36\n"
     ]
    }
   ],
   "source": [
    "people_not_survied = dfTitanic[dfTitanic['Survived']== 0]\n",
    "people_survied = dfTitanic[dfTitanic['Survived']== 1]\n",
    "#print(people_survied['Survived'].count())\n",
    "\n",
    "#count women in first class\n",
    "women = people_survied.loc[(people_survied[\"Pclass\"] == 1 ) & (people_survied[\"Sex\"] == \"female\")].count()\n",
    "\n",
    "#count men in first class\n",
    "men = people_survied.loc[(people_survied[\"Pclass\"] == 1 ) & (people_survied[\"Sex\"] == \"male\")].count()\n",
    "print(\"Women survived in first class:\", women[\"Survived\"])\n",
    "print(\"Men survived in first class:\", men[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women survived in second class: 54\n",
      "Men survived in second class: 16\n"
     ]
    }
   ],
   "source": [
    "#count women in second class\n",
    "women2 = people_survied.loc[(people_survied[\"Pclass\"] == 2 ) & (people_survied[\"Sex\"] == \"female\")].count()\n",
    "\n",
    "#count men in second class\n",
    "men2 = people_survied.loc[(people_survied[\"Pclass\"] == 2 ) & (people_survied[\"Sex\"] == \"male\")].count()\n",
    "print(\"Women survived in second class:\", women2[\"Survived\"])\n",
    "print(\"Men survived in second class:\", men2[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women survived in third class: 62\n",
      "Men survived in third class: 39\n"
     ]
    }
   ],
   "source": [
    "#count women in third class\n",
    "women3 = people_survied.loc[(people_survied[\"Pclass\"] == 3 ) & (people_survied[\"Sex\"] == \"female\")].count()\n",
    "\n",
    "#count men in third class\n",
    "men3 = people_survied.loc[(people_survied[\"Pclass\"] == 3 ) & (people_survied[\"Sex\"] == \"male\")].count()\n",
    "print(\"Women survived in third class:\", women3[\"Survived\"])\n",
    "print(\"Men survived in third class:\", men3[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women survived rate in first class: % 25.806451612903224\n",
      "\n",
      "\n",
      "Men survived rate in first class: % 12.903225806451612\n",
      "\n",
      "\n",
      "Women survived rate in second class: % 19.35483870967742\n",
      "\n",
      "\n",
      "Men survived rate in second class: % 5.734767025089606\n",
      "\n",
      "\n",
      "Women survived rate in third class: % 22.22222222222222\n",
      "\n",
      "\n",
      "Men survived rate in third class: % 13.978494623655912\n"
     ]
    }
   ],
   "source": [
    "people_in_allClass = people_survied[\"Pclass\"].count()\n",
    "\n",
    "female_rate1 = (women/people_in_allClass) * 100\n",
    "men_rate1 = (men/people_in_allClass) * 100\n",
    "print(\"Women survived rate in first class: %\",female_rate1['Survived'])\n",
    "print(\"\\n\")\n",
    "print(\"Men survived rate in first class: %\",men_rate1['Survived'])\n",
    "print(\"\\n\")\n",
    "female_rate2 = (women2/people_in_allClass) * 100\n",
    "men_rate2 = (men2/people_in_allClass) * 100\n",
    "print(\"Women survived rate in second class: %\",female_rate2['Survived'])\n",
    "print(\"\\n\")\n",
    "print(\"Men survived rate in second class: %\",men_rate2['Survived'])\n",
    "print(\"\\n\")\n",
    "female_rate3 = (women3/people_in_allClass) * 100\n",
    "men_rate3 = (men3/people_in_allClass) * 100\n",
    "print(\"Women survived rate in third class: %\",female_rate3['Survived'])\n",
    "print(\"\\n\")\n",
    "print(\"Men survived rate in third class: %\",men_rate3['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part (c) <br>\n",
    "(i) First Class: Women were more survied than men. <br>\n",
    "    Second Class: Women were more survied than men.<br>\n",
    "    Third Class: Women were more survied than men.\n",
    "    \n",
    "(ii) Women in the first class had a higher survival rate.<br>\n",
    "(iii) Wemen in the third class had a higher survial rate than men in first class.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Plot a histogram of all of the passenger ages, using the bin edges $[0,5,10,\\ldots,70,75,80]$ defined by `my_bins` below. How would you characterize the distribution of **AGE**? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Be sure to label your axes and use your figure to justify your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bins = range(0,85,5)\n",
    "#print(\"bin edges = \", list(my_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize figure \n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "\n",
    "\n",
    "# Plot histogram \n",
    "dfTitanic.hist(column=\"Age\", density = True, ax=ax, bins=my_bins, facecolor=\"green\", edgecolor=\"white\");\n",
    "\n",
    "#add a title\n",
    "ax.set_title(\"All Passenger Ages\", fontsize=20)\n",
    "\n",
    "#add axis label\n",
    "ax.set_xlabel(\"Age\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequence\", fontsize=16)\n",
    "\n",
    "# Make the grid lines lighter and put them behind data \n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_axisbelow(True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data of this histogram is unimodal and positve skew. Most of passengers are between age 20 to to 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: One might wonder how a passenger's age is related to the likelihood that they would survive the Titanic disaster. To answer this question graphically, plot two density histograms on the same set of axes, showing the distribution of the ages of passengers who survived, and the distribution of the ages of passengers who did not. \n",
    "* Use the bin edges $[0,5,10,\\ldots,70,75,80]$ for both histograms.\n",
    "* This problem is about a *ship* sinking in the *ocean*, so use **coral** and **seagreen** as the facecolors for your histogram boxes.\n",
    "* Plot both histograms on a single set of axes (there should be only one panel in the figure you create), but use Matplotlib/Pandas plotting functionality to make the faces of the histogram boxes somewhat transparent, so both histograms are visible.\n",
    "* Include a legend and label your axes.\n",
    "* Comment on the results. Does your figure suggest that some age ranges are more or less likely to have survived the disaster than other ages? Fully explain your reasoning and use your figure to justify your conclusions.\n",
    "* If you noticed some relationship between age and likelihood of survival, what is one possible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAEgCAYAAADPIrsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XucXEWd9/HPlwzJEASiwQsmgwkGENBFJVwUduUiEHeFoIBEEaKCcVXWGz4KzwoBFtbFxxV1YVmjIBe5CqJRoyAgXgEJggsBIhGCCSAQSUIEBpjwe/6omubQ6bn0TM/p6c73/Xr1q7vr1KlTlenO+XWdqjqKCMzMzMwANmh2BczMzGz0cGBgZmZmFQ4MzMzMrMKBgZmZmVU4MDAzM7MKBwZmZmZW4cDArE6STpIUkvasSg9JNzSnVmZmjeHAwCyT9K/55B6Sti3heFH1WCtphaTrJR0+0se34ZN0eOHvt1+z62PWCB3NroDZaCBJwFFAAAI+DHy2pMOfnJ83BLYFDgL2krRTRHympDrY0Mzhhc/MHOCa5lbHbPjcY2CW7AdMBc4HHgFmSxpbxoEj4qT8+NeIOATYn3Sy+ZSkKWXUweqXe5X+AbgO+D1woKRXNrdWZsPnwMAs+XB+/iZwEbA58K5mVCQirgPuIf0K3bk3XdIHJF0p6T5JT0t6QtJvJL2/VjmStpI0T9KSnP9xSXdI+h9JEwv5xkr6hKTfS1op6SlJSyX9QNLba5T7OknnSVom6RlJj0i6uNbll5wvJE2R9JF8/O68zzxJm/VR9/1z257M9f5+4bhRK2CStKukKyT9RdKzuX7fkPTqGnlvyOWMlXSipMW5LefVqk8fej8z3wbOI/X4fKCvzJI2k/RVScvzv8E9kj6T/05R69iSxks6XtLt+d/ib5JulPTeGnklabak30p6LB9jmaSrJR1WR7tsPedLCbbey7/yDgT+GBG/lfQE8BlS1/BlzapWfi7ezORs4C7gl8DDwETgH4ELJW0bESdUdpa2AG4BNgUWAFcCnaRekSOAM4G/5uznAe8F7gQuAJ4GXg3sAcwAri2UOwP4Hukk+ENgCTAZeDfwT5L2iojf12jPl0g9IT8kdbfvRTqxTgP2flHD00nsYuAZ4PLc1rcCNwJ/qPmPJX2QFNQ9A8wHlgFbA0cDB0jaLSL+XGPXK0nB10+A7wOP1iq/xvHGArOBJ4CrgPHAl4GjJX0pqm5CI6kTuB54M3AbKfjcDPhX4O/7OMaEvM+bSD0S55J+zO0PXCxph4j4QmGX04DjgftJ/26rgS1y+w6leZ9lazUR4Ycf6/UDOI50Aj6+kHYr8DwwrUb+k3L+PavSA7ihjuNG+gquk/72fOzngdcU0l9bI+9YUlf2c8CkQvq/5PI/WWOfjYGN8uvN8nEWAmNq5J1YeP1SYCWwAti+Kt8OwN+A31eln5fr8Wdgy0J6BynACWCXQvom+RjPADtWlfUfvf9mwJRC+jbAs6QgZVLVPnsDa4GrqtJvyOX8L7D5ED4zs/L+3yikXZnT9qmR/4S87RJAhfQu4LG87bw+/u0+V5XeCfw0/93eWEj/K7AcGF/j+HW30Y/19+FLCbZey4MOjyb9J3tBYdN5pF/tR5dQh5Py4zRJV5D+0xfw1Yh4oDdfRPypet+IeBY4i3Si3adG8U/X2OfJiOhN7x049wzp36A6718Lb48EJgBzI+KuqnyLSL/Y3yRp+xr1OCUKv9gjoofUBQ+wSyHfzHyMiyKiunfgVGBVjbI/SurB+GREPFhVr+tJPQgHSNqkxr4nRMSKGukDmZOfzyuk9b7+MOuaTfr3PT4iKr0JEbEM+Gp15nyp5/3Awoj4UnFbRHQDnyf93d5XtetzpECIqn2G0kZbT/lSgq3v9gZeC1xddVK5mNQ1/AFJJ0TEcyNYh7n5OUgnvl8B50TEd4qZJG1JOiHsA2wJbFRVzqTC6/nAvwNnSdofuBr4DXBX1YnpCUk/BA4Abpd0ZT7+zRHxVFX5b8nPO0o6qUY7tsnP25EueRQtrJF/WX5+aSHtTfn519WZI+Jvkm4H9uyjXm+TtDPregUwJtfv1qptv6uRv1+SpuU6LI6IGwubfkIauPouSZv3nowlbUr6jC2LiKU1ilynraTu/zFA9PFvvWF+3q6QdhGpp2iRpO8CvwBujIjVg2yaGeDAwKzWLz8i4q/5hHkw6VfsFSNVgYjQQHkkbUU6ib2UdOK+hnQNeS0whfSLdFyhzAck7UK67DGDNAYAYJmkL0fE1wvFH0YKON7HC1Mnu3PvxWcj4pGc1jtgsdYv4qKX1Eir9Uu/Jz+PKaT1DkZ8hNpqpffW6/8MoV5/GWCfWj5M+rV+XjExInokfQc4ljQI8ct506b5eSht2pnCANQaim36NPAn4EOky2PHAT2SFgDHRsSSfsoxq/ClBFtvSXo5ac0AgEtUteAQKSiAF4KHZvoM6WRxVETsGRGfiIgTIuIkUm/AOiLi7og4LO83nXSi2AD4mqSjCvmejjRdchtST8T7Sb9i38+LA6LeX547RoT6eZw/jHY+kZ/7mvZXK723XpsNUK9fVO9Y7D0ZDEnFmQdfrPGZOTZvKwZPw2nTGQO0aa9CW9ZGxNciYsdc5sGkgZEHAj+VNG7dw5ityz0Gtj6bTRq8dytwex95DgTeLmlqRNxfWs3WNS0/X1lj29v62zFfz78VuFXSb0mD/g4CzqmRdxlwkaRLSFMm95A0MY81uIl0svl70qC9kXBbft6DNAq/QtJLgDfW2OcmYKdcrx+PUL16zSRdmlhM7UsAkGZcbCPpbRHxi3y55j5giqQpNS4n7FGjjN+RxiTUnLEwkIh4lDR75HuSriNdMns9615KMVuHewxsfdY7sPBjEXF0rQfwDUoahDiApfl5z2JiHj+wTt0k7aLai+30pj2V871c0q418m1MmiHQQxrxD2mw4Cpgbr5MUX3MDVR1/4gh+AHp1/Lhknas2vYF0sDEameSBt2dIWmb6o15rYIhnWBr6O09OrGfz8y/V+WFNLB1A1IvQ+XSkaQu4FPVB8kn9ouA6ZJOkLTOjzhJr5U0Nb8eJ2mfYtk5fUPgZflt9ZgRs5rcY2DrpXwC2xa4IyL6G4B2Dmmu+Qclzc2/vpvhv4EPAt/NAwQfJP0CnEGas169gM37gI9L+gVpGt9K0gC4A0gzEHpHwk8CbpJ0N2mu/DLSNfF3Aq8Cvh4Ra6Ay7uIQUvf0TfmX6CLSL9stSYMAJ5Km0w1J/nX9MeA7wG8lFdcx2JE0oO5tFGZQRMQ9kj5E6mFYJOmnwB9JA/S2JP3qfgx43VDrBZBPwm8nTdf8fj9ZLwXOAA6W9C8R8ThpHYeDSNMct5V0DWk8xXt4oQenelbIMaS1GE4BjpD0a9J4hFeTBh3uTFp/4n7SQNRrgaWSbgYeIP0d9s1550fE3cNpv60/HBjY+qr3GvC3+ssUEUslXUv6D/YA0kmxdBHxv5L2Ik3Z+0fSd/cPpEGFq1g3MLiENBjxraRFdTYiBROXAv8ZEXfmfEtJsyL2JHWBbw48TuoqPy7nL9bjOkl/R7qPxP6kk+6zwEOkxXhqXeqot60XS1pJmvt/GCmQ+SUp8Ogd0PdE1T7fkfQH0jX+vUhLXD+Z63UFjVnc52hS79GFeZpoX/V/UtKlpM/YbNI4gafz3+8U4BDSQMH7Sb0LvyIFBtVtekLS20g9D+8jXcbpJAUH9+YyfpazP0kaQLoX6W9+ELCGNBjxo1RdljHrj+oce2Nm1hSSxgD3AeMi4lXNrk+jSPowMA/454j4RrPrY+YxBmY2qkiaIGl8VZpIYwy2JA2qazmqfc+GLlLPSA/wo9IrZVaDLyWY2WizG3BZvg6/lDRXfzfSjIRlpLUZWtGVeTDgraTLP1NIYznGk1ZEfLCffc1K40sJZjaq5EF+pwK7Ay8n/YBZTvpF/e+FBZdaSh5UeQRpQOFmpHtL3AacGREt2Qti7cmBgZmZmVWst5cSNt9885gyZUrDylu7di1jxowZOGMLaJe2tEs7wG0ZrdqlLe3SDnBb+nPrrbeuiIiXD5RvvQ0MpkyZwsKFte7rMjSrVq1iwoRaa6+0nnZpS7u0A9yW0apd2tIu7QC3pT+SHhg4l2clmJmZWYEDAzMzM6twYGBmZmYVDgzMzMyswoGBmZmZVTgwMDMzswoHBmZmZlbhwMDMzMwqHBiYmZlZhQMDa1tjx48t5TjdPd2lHMfMrAzr7ZLI1v7Gjx2PTtaIHyfm+kZkZtY+3GNgZmZmFQ4MzMzMrMKBgZmZmVU4MDAzM7MKBwZmZmZW4cDAzMzMKhwYmJmZWUXpgYGkGZIWS1oi6bga28dJuixvv1nSlJy+i6Tb8+MPkt412DLNzMxscEoNDCSNAc4C3gFsD7xX0vZV2Y4CVkbENOAM4PScficwPSLeCMwAviGpY5BlmpmZ2SCU3WOwC7AkIu6LiGeBS4GZVXlmAufn11cA+0hSRDwVET05vRPoXW5uMGWamZnZIJS9JPIkYFnh/XJg177yRESPpNXARGCFpF2Bc4HXAEfk7YMpEwBJc4A5AF1dXaxatWr4LcrWrFnTsLKarV3aMmHChNKO1cjPUi3t8jcBt2U0apd2gNvSCGUHBrUWrq9eaL7PPBFxM7CDpO2A8yX9ZJBlkvefB8wDmD59ejT6xFHmiWiktVNbylDGv1c7/U3cltGnXdoBbstwlX0pYTnQVXg/GXiorzySOoDNgMeLGSLibuBJ4PWDLNNsxJRxd8Wy7hRpZlZ2j8EtwNaSpgIPArOA91XlmQ/MBm4EDgGuj4jI+yzLlw9eA2wLLAVWDaJMsxHT2dE54ndx9B0czawspQYG+aR+DHA1MAY4NyIWSToFWBgR84FzgAslLSH1FMzKu+8BHCfpOeB54GMRsQKgVplltsvMzKxdlN1jQEQsABZUpZ1YeN0NHFpjvwuBCwdbppmZmdXPKx+amZlZhQMDMzMzq3BgYGZmZhUODMzMzKzCgYGZmZlVODAwMzOzCgcGZmZmVuHAwMzMzCocGJiZmVmFAwMzMzOrcGBgZmZmFQ4MzMzMrMKBgZmZmVU4MDAzM7MKBwZmZmZW4cDAzMzMKhwYmLWA7p7utjqOmY1eHc2ugJkNrLOjE52sET9OzI0RP4aZjW7uMTAzM7MKBwZmZmZW4cDAzMzMKhwYmJmZWYUDAzMzM6twYGBmZmYVpQcGkmZIWixpiaTjamwfJ+myvP1mSVNy+r6SbpV0R37eu7DPDbnM2/PjFeW1yMzMrH2Uuo6BpDHAWcC+wHLgFknzI+KuQrajgJURMU3SLOB04DBgBXBARDwk6fXA1cCkwn6HR8TCUhpiZmbWpsruMdgFWBIR90XEs8ClwMyqPDOB8/PrK4B9JCkibouIh3L6IqBT0rhSam1mZraeKHvlw0nAssL75cCufeWJiB5Jq4GJpB6DXgcDt0XEM4W0b0taC1wJnBoR6yzhJmkOMAegq6uLVatWDbM5L1izZk3Dymq2dmnLhAkTml2FltTI70Ut7fL5gvZpS7u0A9yWRig7MKi1pmv1CbzfPJJ2IF1e2K+w/fCIeFDSJqTA4AjggnUKiZgHzAOYPn16NPrE0U4nonZqi9WnjL99O32+2qUt7dIOcFuGq+xLCcuBrsL7ycBDfeWR1AFsBjye308GrgKOjIg/9e4QEQ/m5zXAxaRLFmZmZlansgODW4CtJU2VNBaYBcyvyjMfmJ1fHwJcHxEhaQLwY+D4iPhNb2ZJHZI2z683BN4J3DnC7TAzM2tLpQYGEdEDHEOaUXA3cHlELJJ0iqQDc7ZzgImSlgCfAXqnNB4DTANOqJqWOA64WtL/ArcDDwLfLK9VZmZm7aP02y5HxAJgQVXaiYXX3cChNfY7FTi1j2J3amQdzczM1lde+dCaorunu9lVMDOzGkrvMTAD6OzoRCfXmoDSODF3nRmrZmY2APcYmJmZWYUDAzMzM6twYGBmZmYVDgzMzMyswoGBmZmZVTgwMDMzs4ohBQZKXidpd0kbN7pSZmZm1hx1BwaSPkK68dEi4JfAtjn9e5I+3tjqmZmZWZnqCgwkfQj4b+AnwOG8+BbJv6XGUsZmZmbWOurtMfgscEZEfAj4btW2e4DXNaRWZmZm1hT1BgavpeoGSAVrgAnDq46ZmZk1U72BwQrgNX1s24Y09sDMzMxaVL2BwY+AEyRNKaSFpJcBnwZ+0KB6mZmZWRPUGxh8AVhLmpHwUyCAM4C7SQMRT25o7czMzKxUdQUGEfEYMB34MrAJ8ACwMTAP2C0iVjW8hmZmZlaajnp3iIjVwNz8MDMzszZS7zoG0yTt0ce23SW9tjHVMjMzs2aod4zB14B397HtXaTxBmZmZtai6g0MdgZu6GPbDcCuw6mMmZmZNVe9gcGmQHcf254FNhtedczMzKyZ6g0M7gP26mPbXqRZCmZmZtai6g0MvgN8RtJHJG0IIGnDfMfFTwMXDFSApBmSFktaIum4GtvHSbosb7+5dzElSftKulXSHfl578I+O+X0JZK+LknV5ZqZmdnA6g0MTifdWfFs4ClJDwFP5vcLgP/ob2dJY4CzgHcA2wPvlbR9VbajgJURMY00mPH0nL4COCAi3gDMBi4s7HM2MAfYOj9m1NkuMzMzo851DCJiLXCQpP2AfYGJpBP2NRFx7SCK2AVYEhH3AUi6FJgJ3FXIMxM4Kb++AjhTkiLitkKeRUCnpHHAy4BNI+LGXOYFwEGkAMbM6tDd001nR+eIHmPs+LEjWr6ZDU/dCxwBRMQ1wDVD2HUSsKzwfjnrzmSo5ImIHkmreSEA6XUwcFtEPCNpUi6nWOakWgeXNIfUs0BXVxerVjVuocY1a9Y0rKxmK6MtEyb4RpyjUWdHJzp5ZK/Exdxo6Hevmdrle98u7QC3pRGGFBgA5BsnrfPTIiL6u8Nirf9xop48knYgXV7Yr44ye+s2j7R8M9OnT49Gn5za6WTXTm2x0aedPl/t0pZ2aQe4LcNVV2AgaRPgK8AsYHwf2cb0U8RyoKvwfjLr3qq5N89ySR2kKZCP5+NPBq4CjoyIPxXyTx6gTDMzMxuEensMzgTeA5wH3AE8U+f+twBbS5oKPEgKMN5XlWc+aXDhjcAhwPUREZImAD8Gjo+I3/RmjoiHJa2RtBtwM3Ak8F911svMzMyoPzB4B/C5iBjSiTePGTgGuJrUs3BuRCySdAqwMCLmA+cAF0paQuopmJV3PwaYBpwg6YSctl9EPAp8lBSsbEQadOiBh2ZmZkNQb2CwAXD3cA4YEQtIUxuLaScWXncDh9bY71Tg1D7KXAi8fjj1MjMzs/rXMbgc+KeRqIiZmZk1X709Bj8Cvi5pY9Kv/serM0TELxtRMTMzMyvfUAIDgK2Ao3nxtEDl9/3NSjAzM7NRrN7AYN8RqYWZmZmNCvUuiXzdSFXEzMzMmm9IKx9KeilpKeOJwIKIWClpw4h4rqG1MzMzs1LVOysBSV8krSy4gHSb5al5048lfaGBdTMzM7OS1RUYSPo88Gngi8DuvPg+BT/EUxnNzMxaWr2XEuYA/xYRp0mqnn1wL2llQjMzM2tR9V5KmAz8to9tzwIvGV51zMzMrJnqDQweAnboY9sbgKXDqo2ZmZk1Vb2BwRXAiZJ2LaSFpNcCnwUua1jNzMzMrHT1BgYnAUtIlxN6b6Z0KXAncD9pUKKZmZm1qHoXOHpS0j8ARwD7A8uBvwJfAi7wOgZmZmatre4FjiKiB/h2fpiZmVkbqXuBIzMzM2tfdfUYSLqXF99RsVpExLbDq5KZmZk1S72XEm5m3cBgIrAb8ATwy0ZUyszMzJqj3sGH76+VLullwE+BHzeiUmZmZtYcDRljEBGPk2YmzG1EeWZmZtYcjRx8+BSwZQPLMzMzs5LVPV2xmqQNgO2BE3lh0SMzMzNrQfXOSniOdQcfbkC6/fLf8G2XzczMWlq9PQans25g0A08APw4IlYOVICkGcDXgDHAtyLiP6q2jwMuAHYirap4WEQslTSRdK+GnYHzIuKYwj43AFsAT+ek/SLi0TrbZmZmtt6rd1bCF4ZzMEljgLOAfUnLKd8iaX5E3FXIdhSwMiKmSZpFCkYOIwUgJwCvz49qh0fEwuHUz8zMbH1X9sqHuwBLIuK+iHiWdAOmmVV5ZgLn59dXAPtIUkQ8GRG/JgUIZmZmNgLqHWMwr47sEREfqUqbBCwrvF8O7NpXnojokbSatIjSigGO921Ja4ErgVMjor8VGs3MzKyGescYvAPYBNgUeB5YCbyU1PPwBLCmkLfWiVk10qrzDSZPtcMj4kFJm5ACgyNI4xReXLA0B5gD0NXVxapVqwYodvDWrFkzcKYWUUZbJkyYMOLHsNGrkd+9ZmqX7327tAPclkaoNzB4D3AZ8DHguxHxnKQNc/oXgfdExE397L8c6Cq8nww81Eee5ZI6gM2Ax/urVEQ8mJ/XSLqYdMlincAgIuYB8wCmT58ejT45tdPJrp3aYqNPO32+2qUt7dIOcFuGq94xBmcAX4qIiyPiOYCIeC4iLgL+H2m2QX9uAbaWNFXSWGAWML8qz3xgdn59CHB9f5cFJHVI2jy/3hB4J3Bnne0yMzMz6u8x2JE0M6CWxcAb+ts5jxk4BriaNF3x3IhYJOkUYGFEzAfOAS6UtITUUzCrd39JS0mXMcZKOgjYjzRV8uocFIwBrgW+WWe7zMzMjPoDg0dIv+J/VmPbocCAawdExAJgQVXaiYXX3bmsWvtO6aPYnQY6rpmZmQ2s3sDga8B/SnoV8F1SoPBK0hiDfwKObWz1zMzMrEz1LnB0hqSnSJcTDihsegj4aB7cZ2ZmZi2q7psoRcQ3JH0TeA1pGeKHgQci4vlGV87MzMzKNaS7K+Yg4P78MDMzszZR95LIkv5O0uWS/iLpWUlvzumnStqv8VU0MzOzstQVGEh6K3Azadri90jTA4tl/XPjqmZm7ai7Z+Rvd1LGMcza1VBuu3wdcCDrBgILgcMbVC8za1OdHZ3o5FornzdOzPWtUsyGqt7AYCfg4Ih4XlL1N3sFaeqimZmZtah6xxg8A2zUx7ZXAauHVx0zMzNrpnoDg18Dn5BU3K+3z+5DwM8bUiszMzNrinovJZxICg5uI618GMD7JX0J2I10V0MzMzNrUXX1GETEbcCewCrgJEDAp4BOYK+IuLvB9TMzM7MSDWXlw1uAt0kaD2wOrIyINQ2vmZmZmZVu0D0GksZKelTSAQAR8VRE/NlBgZmZWfsYdGAQEc+SLh145RAzM7M2Ve+shPnAwSNRETMzM2u+escYzAfOlHQp8H3SnRVftMRYRPyyQXUzMzOzktUbGFyVn9+TH8WgQPn9mOqdzMzK1N3TTWdH54gfZ+z4sSN+DLOy1RsY7DsitTAza6Ay7scAvieDtacBAwNJewO/i4i/RcR1JdSpJZXxy6GsX0FmZrb+GkyPwc+AtwC/A8jLId8AHBUR945c1VrL+LHjfcc4MzNreYOZlVB9thOwB7BJ46tjZmZmzVTvdEUzMzNrYw4MzMzMrGKwgcEkSVtJ2grYqjqt+BioIEkzJC2WtETScTW2j5N0Wd5+s6QpOX2ipJ9L+pukM6v22UnSHXmfr0sa+eHIZmZmbWiw0xWvqJH2/T7y9rmOgaQxwFmkaY/LgVskzY+IuwrZjiLdmGmapFnA6cBhpKWYTwBenx9FZwNzgJuABcAM4CcDNcrMzMxebDCBwQcbeLxdgCURcR9AXkFxJlAMDGaSbukMKSA5U5Ii4kng15KmFQuUtAWwaUTcmN9fAByEAwMzM7O6DRgYRMT5DTzeJGBZ4f1yYNe+8kREj6TVwERgRT9lLq8qc1KtjJLmkHoW6OrqYtWqVfXWv08TJkxoWFn9aWSd+7JmzcjfMLOsfy+zkVbGd3KklfGdL4vbMnz1rnw4XLWu/VdPzh9MniHlj4h5wDyA6dOnRyuenMqqcyv+25g1Q7t8V9qlHeC2DFfZsxKWA12F95OBh/rKI6kD2Ax4fIAyJw9QppmZmQ1C2YHBLcDWkqZKGgvMIt2xsWg+MDu/PgS4PiL67DGIiIeBNZJ2y7MRjgR+0Piqm5mZtb9SLyXkMQPHAFeTZi+cGxGLJJ0CLIyI+cA5wIWSlpB6Cmb17i9pKbApMFbSQcB+eUbDR4HzgI1Igw498NDMzGwIyh5jQEQsIE0pLKadWHjdDRzax75T+khfyLpTGM3MzKxOXvnQzMzMKhwYmJkNUXdPd1scw6yo9EsJZmbtorOj07dbt7bjHgMzMzOrcGBgZmZmFQ4MzMzMrMKBgZmZmVU4MDAzM7MKBwZmZmZW4cDAzMzMKhwYmJmZWYUDAzMzM6twYGBmZmYVDgzMzMyswoGBmZmZVTgwMDMzswoHBmZmZlbhwMDMzMwqHBiYmZlZhQODFtLd013KccaOH1vKcczMbPTpaHYFbPA6OzrRyRrx48TcGPFjmJnZ6OQeAzMzM6twYGBmZmYVpQcGkmZIWixpiaTjamwfJ+myvP1mSVMK247P6Ysl7V9IXyrpDkm3S1pYTkvMzMzaT6ljDCSNAc4C9gWWA7dImh8RdxWyHQWsjIhpkmYBpwOHSdoemAXsALwauFbSNhGxNu+3V0SsKK0xZmZmbajsHoNdgCURcV9EPAtcCsysyjMTOD+/vgLYR5Jy+qUR8UxE3A8syeWZmZlZg5Q9K2ESsKzwfjmwa195IqJH0mpgYk6/qWrfSfl1ANdICuAbETGv1sElzQHmAHR1dbFq1arhtaZgwoQJDStrNGjkv00t7fbvZTaSRvr7uGbNmhEtv0xuy/CVHRjUmmtXPTeurzz97bt7RDwk6RXAzyTdExG/XCdzChjmAUyfPj18cuqb/23MRo8yvo/t9J13W4an7EsJy4GuwvvJwEN95ZHUAWwGPN7fvhHR+/wocBW+xGBmZjYkZQcGtwBbS5oqaSxpMOH8qjzzgdn59SHA9REROX1WnrUwFdga+J2kjSVtAiBpY2A/4M4S2mJmZtZ2Sr2UkMcMHANcDYwBzo2IRZJOARZGxHzgHOBCSUtIPQWz8r6LJF0O3AX0AB+PiLWSXglclcYn0gFcHBE/LbNd7aa7p5vOjs5mV8PMKOe6QEkHAAAJ0ElEQVT76GXQraj0JZEjYgGwoCrtxMLrbuDQPvY9DTitKu0+YMfG13T9VcbSy1522Wxw/H20snnlQzOz9VxZN2gr6zg2PL6JkpnZes43aLMi9xiYmZlZhQMDMzMzq3BgYGZmZhUODMzMzKzCgYGZmZlVODAwMzOzCgcGZmZmVuHAwMzMzCocGJiZmVmFAwMzMzOrcGBgZmZmFQ4MzMzMrMKBgZmZmVU4MDAzM7MKBwZmZtY2xo4fO+LH6O7pHvFjNFNHsytgZmbWKOPHjkcna0SPEXNjRMtvNvcYmJmZWYUDAzMzM6twYGBmZqVo92vz7cJjDMzMrBSdHZ2+/t8C3GNgZmZmFQ4MzMzMrKL0wEDSDEmLJS2RdFyN7eMkXZa33yxpSmHb8Tl9saT9B1ummZmZDU6pgYGkMcBZwDuA7YH3Stq+KttRwMqImAacAZye990emAXsAMwA/lvSmEGWaWZm1hBlDaIsY7GmWsoefLgLsCQi7gOQdCkwE7irkGcmcFJ+fQVwpiTl9Esj4hngfklLcnkMokwzM7OGKGMQJTRvIKUiyjuwpEOAGRFxdH5/BLBrRBxTyHNnzrM8v/8TsCspWLgpIr6T088BfpJ367fMQtlzgDn57bbA4gY2b3NgRQPLa6Z2aUu7tAPcltGqXdrSLu0At6U/r4mIlw+Uqeweg1ohVnVk0leevtJrXQ6pGe1ExDxgXn8VHCpJCyNi+kiUXbZ2aUu7tAPcltGqXdrSLu0At6URyh58uBzoKryfDDzUVx5JHcBmwOP97DuYMs3MzGwQyg4MbgG2ljRV0ljSYML5VXnmA7Pz60OA6yNd75gPzMqzFqYCWwO/G2SZZmZmNgilXkqIiB5JxwBXA2OAcyNikaRTgIURMR84B7gwDy58nHSiJ+e7nDSosAf4eESsBahVZpntykbkEkWTtEtb2qUd4LaMVu3SlnZpB7gtw1bq4EMzMzMb3bzyoZmZmVU4MDAzM7MKBwbD1OrLMUs6V9Kjef2I3rSXSfqZpHvz80ubWcfBkNQl6eeS7pa0SNInc3ortqVT0u8k/SG35eScPjUvE35vXja8Ocui1SmvUHqbpB/l963ajqWS7pB0u6SFOa3lPl8AkiZIukLSPfk785ZWbIukbfPfo/fxhKRPtWhbPp2/73dKuiT/P9CU74oDg2Fok+WYzyMtMV10HHBdRGwNXJffj3Y9wLERsR2wG/Dx/LdoxbY8A+wdETsCbwRmSNqNtDz4GbktK0nLh7eCTwJ3F963ajsA9oqINxbmlrfi5wvga8BPI+J1wI6kv0/LtSUiFue/xxuBnYCngKtosbZImgR8ApgeEa8nDaSfRbO+KxHhxxAfwFuAqwvvjweOb3a9htCOKcCdhfeLgS3y6y2Axc2u4xDa9ANg31ZvCzAe+D1p9c8VQEdOf9Fnb7Q+SOuKXAfsDfyItFBZy7Uj13UpsHlVWst9voBNgfvJg89buS1V9d8P+E0rtgWYBCwDXkaaLfgjYP9mfVfcYzA8vX/MXstzWqt7ZUQ8DJCfX9Hk+tRF6Y6cbwJupkXbkrvfbwceBX4G/AlYFRE9OUurfNa+CnwOeD6/n0hrtgPSiqrXSLo1L68Orfn52gp4DPh2vsTzLUkb05ptKZoFXJJft1RbIuJB4MvAn4GHgdXArTTpu+LAYHgGs8SzlUjSS4ArgU9FxBPNrs9QRcTaSN2jk0k3C9uuVrZya1UfSe8EHo2IW4vJNbKO6nYU7B4RbyZdOvy4pH9odoWGqAN4M3B2RLwJeJJR3tU+kHzt/UDgu82uy1DkMRAzganAq4GNSZ+zaqV8VxwYDE+7Lsf8iKQtAPLzo02uz6BI2pAUFFwUEd/LyS3Zll4RsQq4gTRuYkJeJhxa47O2O3CgpKXApaTLCV+l9doBQEQ8lJ8fJV3H3oXW/HwtB5ZHxM35/RWkQKEV29LrHcDvI+KR/L7V2vJ24P6IeCwingO+B7yVJn1XHBgMT7sux1xclno26Xr9qCZJpFUz746IrxQ2tWJbXi5pQn69Eek/jbuBn5OWCYcWaEtEHB8RkyNiCum7cX1EHE6LtQNA0saSNul9TbqefSct+PmKiL8AyyRtm5P2Ia0o23JtKXgvL1xGgNZry5+B3SSNz/+X9f5NmvJd8cqHwyTpH0m/gnqXYz6tyVWqi6RLgD1Jt/d8BJgLfB+4HNiS9IE9NCIeb1YdB0PSHsCvgDt44Xr2/yWNM2i1tvwdcD7pM7UBcHlEnCJpK9Iv75cBtwHvj4hnmlfTwZO0J/DZiHhnK7Yj1/mq/LYDuDgiTpM0kRb7fAFIeiPwLWAscB/wQfJnjdZry3jSWK+tImJ1Tmu5v0uelnwYaYbVbcDRpDEFpX9XHBiYmZlZhS8lmJmZWYUDAzMzM6twYGBmZmYVDgzMzMyswoGBmZmZVTgwMLNhyUvqhqSvDJzbzEY7T1c0syHLCzD9hXRjnkeBSYW13c2sBbnHwMyG412koGAB6UY11bfwNrMW48DAzIZjNuk+8R8AngaOrM4g6b2S7pHULekOSQdKukHSDVX5Npd0tqQHJT2T95lTXZ6ZjayOgbOYma1L0qtJ93GYFxGPSfo+8G5JL42IlTnPvsBFpLXrjyUtvf1VoBP4Y6GsTYHfABsBJwH3k+5Hf7akcRHxX6U1zGw958DAzIbqCFKv4wX5/fmkm9kcBvxPTjuZdDOYd0Ue0CTpDtK95v9YKOuTwGuAN0TEvTnt2nwzqbmSzvbYBbNy+FKCmQ3VkcC9EXFjfn8t6bawRwJIGgNMB66MwijniPg9qUegaAbphlf3S+rofQBXAxOB7Ue0JWZW4R4DM6ubpJ1JJ+vTe28RnX0POEbSNsBqYEPSbIVqj1S9fwUwDXiuj0NOHF6NzWywHBiY2VD03uv+8/lR7UjSLbyfI530q72SdDvcXn8lBRCf7ON4i4dWTTOrl9cxMLO6SBpLumSwBDiuRpYzSPePn0IaULgpaexA7xiDnYCFwC8iYs+cdhLwL8B2EVGrh8HMSuLAwMzqIundwJXAByLi/Brb/xk4G9ib1Ct5DfADYB5pVsJJpNkHd0fE3nmfzYCbSOOeziD1EGwMvA74+4iYObKtMrNeHnxoZvWaDawBvtvH9ktIaxrMjoifAYcD2wFXkS47HEtaLXF17w4RsRp4K2mhpM+TBh2eC8wEfj4irTCzmtxjYGalkjSZdBnitIj4t2bXx8xezIGBmY2YfC+Fr5CmMq4AtgI+Rxp8uENEPNzE6plZDZ6VYGYjaS3wKuBM0pTDJ4FfAYc6KDAbndxjYGZmZhUefGhmZmYVDgzMzMyswoGBmZmZVTgwMDMzswoHBmZmZlbx/wGjWsc6D4vYmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize figure \n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "# Plot histogram \n",
    "dfTitanic.hist(column=\"Age\", density = True, ax=ax, bins=my_bins, facecolor=\"green\", edgecolor=\"white\");\n",
    "\n",
    "#add a title\n",
    "ax.set_title(\"All Passenger Ages\", fontsize=20)\n",
    "\n",
    "#add axis label\n",
    "ax.set_xlabel(\"Age\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequence\", fontsize=16)\n",
    "\n",
    "# Make the grid lines lighter and put them behind data \n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_axisbelow(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F:** In Part E, we plotted two *density* histograms, showing the distributions of ages of passengers that survived or did not survive the Titanic disaster. Why would it be misleading for us to have plotted these as *frequency* histograms instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plotting the resulting DataFrame\n",
    "fig = plt.subplots(figsize = (14, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "\n",
    "N = len(decade_df.index)\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "    \n",
    "bar1=plt.bar(ind, decade_df[\"Embarked\"], width, color=\"#5975A4\", label=\"Embarked\")\n",
    "bar2=plt.bar(ind + width, decade_df[\"Survived\"], width, color='#5F9E6E', label=\"Survived\")\n",
    "\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Number of Passengers\", fontsize=12)\n",
    "plt.title(\"Passengers' that survived or did not\", fontsize=14)\n",
    "plt.xticks(ind + width, decade_df.index.values)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, or some combination of both characteristics in the final hours aboard the Titanic?  Justify your conclusion based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p5'></a>\n",
    "\n",
    "### (25 pts) Problem 5 - FCQ Data from Days of Yore\n",
    "---\n",
    "\n",
    "The `fcq_data.csv` data set on Canvas contains about 12 full academic years of Faculty Course Questionnaire (FCQ) data from the University of Colorado Boulder. The data include the year and term (fall or spring), the course subject and number, the distribution of grades, and other such information. The file `fcq_data_info.xlsx` contains some **metadata**, which describes what all of the columns in the main data file are, and how to interpret some of the measurements. Note that some of the columns from the original data set have been removed in order to make the file size a bit more manageable.\n",
    "\n",
    "First, load the data file, and check out what are all of the available column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['YearTerm', 'Subject', 'Course', 'CourseTitle', 'Activity_Type',\n",
      "       'Hours', 'N_EOT', 'N_ENROLL', 'N_GRADE', 'AVG_GRD', 'PCT_A', 'PCT_B',\n",
      "       'PCT_C', 'PCT_D', 'PCT_F', 'PCT_C_MINUS_OR_BELOW', 'PCT_DF', 'PCT_DFW',\n",
      "       'PCT_WDRAW', 'PCT_INCOMP', 'N_PASS', 'N_NOCRED', 'N_INCOMP',\n",
      "       'Workload_Raw', 'Workload_Hrs_Wk', 'AvgCourse', 'AvgInstructor',\n",
      "       'N_Ret'],\n",
      "      dtype='object')\n",
      "       YearTerm Subject  Course  \\\n",
      "0         20067    ARCH    3114   \n",
      "1         20067    ARCH    3214   \n",
      "2         20067    ARCH    4010   \n",
      "3         20067    ARCH    4010   \n",
      "4         20067    ARCH    4010   \n",
      "5         20067    ENVD    1004   \n",
      "6         20067    ENVD    2001   \n",
      "7         20067    ENVD    2002   \n",
      "8         20067    ENVD    2003   \n",
      "9         20067    ENVD    2052   \n",
      "10        20067    ENVD    2110   \n",
      "11        20067    ENVD    2152   \n",
      "12        20067    ENVD    2352   \n",
      "13        20067    ENVD    3001   \n",
      "14        20067    ENVD    3015   \n",
      "15        20067    ENVD    3022   \n",
      "16        20067    ENVD    3022   \n",
      "17        20067    ENVD    3115   \n",
      "18        20067    ENVD    3122   \n",
      "19        20067    ENVD    3152   \n",
      "20        20067    ENVD    3152   \n",
      "21        20067    ENVD    3152   \n",
      "22        20067    ENVD    3152   \n",
      "23        20067    ENVD    3210   \n",
      "24        20067    ENVD    3212   \n",
      "25        20067    ENVD    3220   \n",
      "26        20067    ENVD    3352   \n",
      "27        20067    ENVD    3352   \n",
      "28        20067    ENVD    3352   \n",
      "29        20067    ENVD    3352   \n",
      "...         ...     ...     ...   \n",
      "74053     20181    MUSC    4203   \n",
      "74054     20181    MUSC    4443   \n",
      "74055     20181    MUSC    4988   \n",
      "74056     20181    MUSC    4997   \n",
      "74057     20181    MUSC    5071   \n",
      "74058     20181    MUSC    5091   \n",
      "74059     20181    MUSC    5151   \n",
      "74060     20181    MUSC    5484   \n",
      "74061     20181    MUSC    5708   \n",
      "74062     20181    MUSC    6203   \n",
      "74063     20181    PMUS    1205   \n",
      "74064     20181    PMUS    1205   \n",
      "74065     20181    PMUS    1506   \n",
      "74066     20181    PMUS    1516   \n",
      "74067     20181    PMUS    1556   \n",
      "74068     20181    PMUS    1596   \n",
      "74069     20181    PMUS    1626   \n",
      "74070     20181    PMUS    1646   \n",
      "74071     20181    PMUS    1656   \n",
      "74072     20181    PMUS    1666   \n",
      "74073     20181    PMUS    1676   \n",
      "74074     20181    PMUS    1696   \n",
      "74075     20181    PMUS    1706   \n",
      "74076     20181    PMUS    1706   \n",
      "74077     20181    PMUS    1716   \n",
      "74078     20181    PMUS    1726   \n",
      "74079     20181    PMUS    1726   \n",
      "74080     20181    PMUS    1726   \n",
      "74081     20181    PMUS    2205   \n",
      "74082     20181    PMUS    4157   \n",
      "\n",
      "                                           CourseTitle    Activity_Type  \\\n",
      "0                               HIST & THEOR OF ARCH 1    LEC - Lecture   \n",
      "1                               HIST & THEOR OF ARCH 2    LEC - Lecture   \n",
      "2                                   ARCH APPREC/DESIGN    LEC - Lecture   \n",
      "3                                   ARCH APPREC/DESIGN    LEC - Lecture   \n",
      "4                                   ARCH APPREC/DESIGN    LEC - Lecture   \n",
      "5                                        INTRO TO ENVD    LEC - Lecture   \n",
      "6                             INTR SOC FACTORS IN ENVD    LEC - Lecture   \n",
      "7                                  ENVD DESIGN MEDIA 1    LEC - Lecture   \n",
      "8                                   ECOLOGY AND DESIGN    LEC - Lecture   \n",
      "9                                COMPUTERS IN PLANNING    LEC - Lecture   \n",
      "10                                   ENV DESIGN STUDIO    LEC - Lecture   \n",
      "11                                    GIS FOR PLANNERS    LEC - Lecture   \n",
      "12                            DIGITAL PRES & PORTFOLIO    LEC - Lecture   \n",
      "13                            ENVIRONMENT AND BEHAVIOR    LEC - Lecture   \n",
      "14                              INTRO HISTORIC PRESERV    LEC - Lecture   \n",
      "15                               TECHNICAL PHOTOGRAPHY    LEC - Lecture   \n",
      "16                               TECHNICAL PHOTOGRAPHY    LEC - Lecture   \n",
      "17                             INTRO BUILD MAT/SYSTEMS    LEC - Lecture   \n",
      "18                               RSCH ISS/METH IN PLAN    LEC - Lecture   \n",
      "19                                    INTRO TO AUTOCAD    LEC - Lecture   \n",
      "20                                    INTRO TO AUTOCAD    LEC - Lecture   \n",
      "21                                    INTRO TO AUTOCAD    LEC - Lecture   \n",
      "22                                    INTRO TO AUTOCAD    LEC - Lecture   \n",
      "23                                       ARCH STUDIO 2    LEC - Lecture   \n",
      "24                                        COLOR THEORY    LEC - Lecture   \n",
      "25                                   PLANNING STUDIO 2    LEC - Lecture   \n",
      "26                                 ARCH COMPUTER MEDIA    LEC - Lecture   \n",
      "27                                 ARCH COMPUTER MEDIA    LEC - Lecture   \n",
      "28                                 ARCH COMPUTER MEDIA    LEC - Lecture   \n",
      "29                                 ARCH COMPUTER MEDIA    LEC - Lecture   \n",
      "...                                                ...              ...   \n",
      "74053                          Music Methods Practicum  PRA - Practicum   \n",
      "74054                      Teaching Instrumental Music    LEC - Lecture   \n",
      "74055                       The Entrepreneurial Artist    LEC - Lecture   \n",
      "74056                                   Senior Recital  IND - Ind Study   \n",
      "74057                 Post-tonal Theory and Analysis I    LEC - Lecture   \n",
      "74058       Contemporary Theory - Jazz and Modal Music    LEC - Lecture   \n",
      "74059                         Topics in Music Analysis    LEC - Lecture   \n",
      "74060               Graduate Seminar in Vocal Pedagogy    SEM - Seminar   \n",
      "74061  Introduction to Music Bibliography and Research    LEC - Lecture   \n",
      "74062                     Psychology of Music Learning    LEC - Lecture   \n",
      "74063                          Keyboard-Musicianship 2    LEC - Lecture   \n",
      "74064                          Keyboard-Musicianship 2    LEC - Lecture   \n",
      "74065                                          Bassoon     STU - Studio   \n",
      "74066                                         Clarinet     STU - Studio   \n",
      "74067                                            Flute     STU - Studio   \n",
      "74068                                             Horn     STU - Studio   \n",
      "74069                                       Percussion     STU - Studio   \n",
      "74070                                        Saxophone     STU - Studio   \n",
      "74071                                      Double Bass     STU - Studio   \n",
      "74072                                         Trombone     STU - Studio   \n",
      "74073                                          Trumpet     STU - Studio   \n",
      "74074                                            Viola     STU - Studio   \n",
      "74075                                           Violin     STU - Studio   \n",
      "74076                                           Violin     STU - Studio   \n",
      "74077                                      Violoncello     STU - Studio   \n",
      "74078                                            Voice     STU - Studio   \n",
      "74079                                            Voice     STU - Studio   \n",
      "74080                                            Voice     STU - Studio   \n",
      "74081                          Keyboard-Musicianship 4    LEC - Lecture   \n",
      "74082                                  Opera Practicum  PRA - Practicum   \n",
      "\n",
      "       Hours  N_EOT  N_ENROLL  N_GRADE  AVG_GRD  ...    PCT_WDRAW  PCT_INCOMP  \\\n",
      "0          3    146       150    145.0     1.98  ...       0.0267      0.0068   \n",
      "1          3    105       109    100.0     3.02  ...       0.0367      0.0476   \n",
      "2          6     16        16     16.0     3.86  ...       0.0000      0.0000   \n",
      "3          6     14        14     14.0     3.74  ...       0.0000      0.0000   \n",
      "4          6     14        14     14.0     3.89  ...       0.0000      0.0000   \n",
      "5          6    159       159    159.0     3.44  ...       0.0000      0.0000   \n",
      "6          3    148       150    147.0     2.86  ...       0.0133      0.0068   \n",
      "7          3    144       150    144.0     3.07  ...       0.0400      0.0000   \n",
      "8          3    200       204    199.0     2.90  ...       0.0196      0.0050   \n",
      "9          3     16        16     16.0     3.61  ...       0.0000      0.0000   \n",
      "10         6     88        88     87.0     3.29  ...       0.0000      0.0114   \n",
      "11         3     10        10     10.0     3.56  ...       0.0000      0.0000   \n",
      "12         3     15        16     15.0     3.22  ...       0.0625      0.0000   \n",
      "13         3    126       129    125.0     3.11  ...       0.0233      0.0079   \n",
      "14         3     28        28     28.0     3.76  ...       0.0000      0.0000   \n",
      "15         3     14        16     14.0     3.59  ...       0.1250      0.0000   \n",
      "16         3     12        12     11.0     3.65  ...       0.0000      0.0833   \n",
      "17         3    155       159    154.0     3.08  ...       0.0252      0.0065   \n",
      "18         3     13        13     13.0     3.46  ...       0.0000      0.0000   \n",
      "19         3     19        20     19.0     3.22  ...       0.0500      0.0000   \n",
      "20         3     18        18     18.0     3.51  ...       0.0000      0.0000   \n",
      "21         3     17        18     17.0     3.39  ...       0.0556      0.0000   \n",
      "22         3     15        15     15.0     3.24  ...       0.0000      0.0000   \n",
      "23         6     74        75     72.0     3.34  ...       0.0133      0.0270   \n",
      "24         3     15        15     15.0     2.61  ...       0.0000      0.0000   \n",
      "25         6     15        15     15.0     3.43  ...       0.0000      0.0000   \n",
      "26         3     15        16     15.0     2.87  ...       0.0625      0.0000   \n",
      "27         3     30        32     30.0     3.87  ...       0.0625      0.0000   \n",
      "28         3     33        34     33.0     3.37  ...       0.0294      0.0000   \n",
      "29         3     26        26     24.0     3.38  ...       0.0000      0.0769   \n",
      "...      ...    ...       ...      ...      ...  ...          ...         ...   \n",
      "74053      1     22        22     22.0     3.75  ...       0.0000      0.0000   \n",
      "74054      3     20        20     20.0     3.29  ...       0.0000      0.0000   \n",
      "74055      3     17        17     16.0     3.26  ...       0.0000      0.0536   \n",
      "74056      1     35        35     35.0     3.89  ...       0.0000      0.0000   \n",
      "74057      3     12        12     12.0     3.55  ...       0.0000      0.0000   \n",
      "74058      3     10        10     10.0     4.00  ...       0.0000      0.0000   \n",
      "74059      3     10        10     10.0     3.84  ...       0.0000      0.0000   \n",
      "74060      2     12        12     12.0     4.00  ...       0.0000      0.0000   \n",
      "74061      2     14        14     14.0     3.59  ...       0.0000      0.0000   \n",
      "74062      2     16        17     16.0     3.69  ...       0.0588      0.0000   \n",
      "74063      1     11        12     11.0     3.53  ...       0.0833      0.0000   \n",
      "74064      1     11        11     11.0     2.45  ...       0.0000      0.0000   \n",
      "74065      3     10        10     10.0     4.00  ...       0.0000      0.0000   \n",
      "74066      3     15        15     15.0     3.98  ...       0.0000      0.0000   \n",
      "74067      2     14        14     13.0     3.95  ...       0.0000      0.0615   \n",
      "74068      3     13        13     13.0     3.88  ...       0.0000      0.0000   \n",
      "74069      3     12        12     12.0     3.75  ...       0.0000      0.0000   \n",
      "74070      2     12        13     12.0     3.87  ...       0.0667      0.0000   \n",
      "74071      3     12        12     12.0     4.00  ...       0.0000      0.0000   \n",
      "74072      3     17        18     17.0     3.65  ...       0.0392      0.0000   \n",
      "74073      3     10        10     10.0     3.84  ...       0.0000      0.0000   \n",
      "74074      3     15        15     15.0     3.80  ...       0.0000      0.0000   \n",
      "74075      3     15        15     15.0     3.96  ...       0.0000      0.0000   \n",
      "74076      3     18        18     18.0     3.97  ...       0.0000      0.0000   \n",
      "74077      3     12        12     12.0     3.59  ...       0.0000      0.0000   \n",
      "74078      4     12        12     12.0     3.97  ...       0.0000      0.0000   \n",
      "74079      3     15        15     15.0     3.81  ...       0.0000      0.0000   \n",
      "74080      3     13        13     12.0     4.00  ...       0.0000      0.0417   \n",
      "74081      1     10        10     10.0     3.63  ...       0.0000      0.0000   \n",
      "74082      1     26        27     26.0     3.99  ...       0.0364      0.0000   \n",
      "\n",
      "       N_PASS  N_NOCRED  N_INCOMP  Workload_Raw  Workload_Hrs_Wk  AvgCourse  \\\n",
      "0           0         0         1          2.45              4-6       3.03   \n",
      "1           0         0         5          2.40              4-6       4.72   \n",
      "2           0         0         0          4.38            10-12       4.54   \n",
      "3           0         0         0          4.11            10-12       3.78   \n",
      "4           0         0         0          4.57            13-15       4.57   \n",
      "5           0         0         0          3.19              7-9       4.93   \n",
      "6           0         0         1          2.55              7-9       4.40   \n",
      "7           0         0         0          4.27            10-12       4.44   \n",
      "8           0         0         1          2.13              4-6       3.69   \n",
      "9           0         0         0          2.08              4-6       4.86   \n",
      "10          0         0         1          5.58              16+       4.43   \n",
      "11          0         0         0          2.00              4-6       5.11   \n",
      "12          0         0         0          3.50            10-12       5.75   \n",
      "13          0         0         1          2.08              4-6       4.53   \n",
      "14          0         0         0          2.05              4-6       5.13   \n",
      "15          0         0         0          4.20            10-12       5.50   \n",
      "16          0         0         1          5.38            13-15       5.78   \n",
      "17          0         0         1          2.29              4-6       3.83   \n",
      "18          0         0         0          2.40              4-6       2.64   \n",
      "19          0         0         0          2.50              7-9       5.13   \n",
      "20          0         0         0          2.27              4-6       5.63   \n",
      "21          0         0         0          2.40              4-6       5.09   \n",
      "22          0         0         0          3.09              7-9       4.77   \n",
      "23          0         0         2           NaN              NaN        NaN   \n",
      "24          0         0         0           NaN              NaN        NaN   \n",
      "25          0         0         0          4.00            10-12       5.00   \n",
      "26          0         0         0          3.00              7-9       4.31   \n",
      "27          0         0         0          3.19              7-9       5.54   \n",
      "28          0         0         0          2.71              7-9       5.12   \n",
      "29          0         0         2          2.88              7-9       5.18   \n",
      "...       ...       ...       ...           ...              ...        ...   \n",
      "74053       0         0         0          2.56              7-9       4.11   \n",
      "74054       0         0         0          2.94              7-9       2.59   \n",
      "74055       0         0         1          2.08              4-6       5.17   \n",
      "74056       0         0         0           NaN              NaN        NaN   \n",
      "74057       0         0         0          2.38              4-6       4.00   \n",
      "74058       0         0         0          2.40              4-6       5.50   \n",
      "74059       0         0         0          3.00              7-9       6.00   \n",
      "74060       0         0         0          2.00              4-6       4.67   \n",
      "74061       0         0         0          2.07              4-6       4.57   \n",
      "74062       0         0         0          2.40              4-6       4.20   \n",
      "74063       0         0         0          1.70              4-6       4.00   \n",
      "74064       0         0         0          1.90              4-6       3.80   \n",
      "74065       0         0         0          4.14            10-12       5.57   \n",
      "74066       0         0         0          5.50              16+       5.92   \n",
      "74067       0         0         1          4.91            13-15       5.64   \n",
      "74068       0         0         0          5.33            13-15       5.55   \n",
      "74069       0         0         0          4.80            13-15       3.80   \n",
      "74070       0         0         0          4.43            10-12       5.71   \n",
      "74071       0         0         0          5.40            13-15       5.80   \n",
      "74072       0         0         0          4.64            13-15       5.93   \n",
      "74073       0         0         0          5.25            13-15       5.75   \n",
      "74074       0         0         0          5.18            13-15       5.91   \n",
      "74075       0         0         0          5.21            13-15       5.57   \n",
      "74076       0         0         0          5.58              16+       5.92   \n",
      "74077       0         0         0          5.80              16+       5.90   \n",
      "74078       0         0         0          3.80            10-12       5.80   \n",
      "74079       0         0         0          2.93              7-9       5.80   \n",
      "74080       0         0         1          3.33              7-9       5.67   \n",
      "74081       0         0         0          1.90              4-6       3.50   \n",
      "74082       0         0         0          4.25            10-12       5.00   \n",
      "\n",
      "       AvgInstructor  N_Ret  \n",
      "0               2.91   78.0  \n",
      "1               4.76   54.0  \n",
      "2               4.62   13.0  \n",
      "3               4.00    9.0  \n",
      "4               4.43   14.0  \n",
      "5               5.10   74.0  \n",
      "6               4.92   96.0  \n",
      "7               4.52   82.0  \n",
      "8               4.24  139.0  \n",
      "9               5.50   16.0  \n",
      "10              4.14   71.0  \n",
      "11              5.33   10.0  \n",
      "12              5.63    8.0  \n",
      "13              4.93   95.0  \n",
      "14              5.48   24.0  \n",
      "15              5.38    8.0  \n",
      "16              5.89    9.0  \n",
      "17              3.75   95.0  \n",
      "18              3.18   11.0  \n",
      "19              5.50   15.0  \n",
      "20              5.88   16.0  \n",
      "21              5.45   11.0  \n",
      "22              5.23   13.0  \n",
      "23               NaN    0.0  \n",
      "24               NaN    0.0  \n",
      "25              5.14   15.0  \n",
      "26              4.23   13.0  \n",
      "27              5.83   24.0  \n",
      "28              5.12   26.0  \n",
      "29              5.35   17.0  \n",
      "...              ...    ...  \n",
      "74053           4.09    9.0  \n",
      "74054           3.44   17.0  \n",
      "74055           5.42   12.0  \n",
      "74056            NaN    NaN  \n",
      "74057           4.38    8.0  \n",
      "74058           5.60   10.0  \n",
      "74059           6.00    9.0  \n",
      "74060           5.33    3.0  \n",
      "74061           5.29   14.0  \n",
      "74062           4.73   15.0  \n",
      "74063           5.60   10.0  \n",
      "74064           4.60   10.0  \n",
      "74065           5.71    7.0  \n",
      "74066           5.92   12.0  \n",
      "74067           5.91   11.0  \n",
      "74068           5.44    9.0  \n",
      "74069           3.40    5.0  \n",
      "74070           5.86    7.0  \n",
      "74071           6.00    5.0  \n",
      "74072           6.00   14.0  \n",
      "74073           5.00    4.0  \n",
      "74074           5.91   11.0  \n",
      "74075           5.50   14.0  \n",
      "74076           5.83   12.0  \n",
      "74077           5.90   10.0  \n",
      "74078           6.00    5.0  \n",
      "74079           5.80   15.0  \n",
      "74080           5.78    9.0  \n",
      "74081           5.70   10.0  \n",
      "74082           5.40    8.0  \n",
      "\n",
      "[74083 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"fcq_data.csv\")\n",
    "print(df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:** Suppose we want to restrict our attention to only undergraduate classes in the Computer Science department. Create a new DataFrame called `dfC` consisting only of undergraduate computer science classes. You may decide for yourself how to obtain only the rows corresponding to **undergraduate** and **computer science** courses. How many data points are there total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points in computer science are  617\n"
     ]
    }
   ],
   "source": [
    "dfc = df[df['Subject'] == 'CSCI'].copy()\n",
    "cs_under = dfc[dfc['Course'] < 5000]\n",
    "print(\"Total data points in computer science are \",cs_under['Course'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Using the undergraduate computer science courses DataFrame and the `isnull()` and/or `notnull()` (or `isna`/`notna`) methods in Pandas, determine which column(s) in are missing any data. Also using Pandas methods, report how many values are missing from each of those column(s). Finally, use the `dropna()` method to remove any rows that are missing data. For the remainder of this problem, use the cleaned DataFrame for analysis. How many data points are there in the cleaned DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_under.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B:<br>\n",
    "Workload_Raw = 52<br>\n",
    "Workloand_Hrs_Wk = 52<br>\n",
    "AvgCourse = 52<br>\n",
    "AvgInstructor 52<br>\n",
    "N_Ret = 42<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** One might hypothesize that students' grades are higher in one credit-hour courses than in regular lecture sections. Note that `Hours` corresponds to the number of credit-hours a class is worth, and that Average Grades are provided in the data set on a GPA-scale (4=A, 3=B, and so on).\n",
    "\n",
    "Compute the mean and median Average Grade for all undergraduate Computer Science courses, and for only the one credit-hour undergraduate Computer Science courses. Report all four of these numbers, and comment on the results. Does your calculation seem to support our hypothesis or not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_credit_hours = cs_under[cs_under['Hours'] == 1]\n",
    "two_credit_hours = cs_under[cs_under['Hours'] == 2]\n",
    "three_credit_hours = cs_under[cs_under['Hours'] == 3]\n",
    "four_credit_hours = cs_under[cs_under['Hours'] == 4]\n",
    "#print(\"Mean Average Grade: \", one_credit_hours['AVG_GRD'].mean())\n",
    "#print(\"Median Average Grade: \", one_credit_hours['AVG_GRD'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Average Grade in one credit-hour:  $3.708548387096774$<br>\n",
    "Median Average Grade one credit-hour:  $3.85$<br>\n",
    "\n",
    "Mean Average Grade in two credit-hour:  $3.72$<br>\n",
    "Median Average Grade two credit-hour:  $3.72$<br>\n",
    "\n",
    "Mean Average Grade in three credit-hour:  $3.468784029038116$<br>\n",
    "Median Average Grade three credit-hour:  $3.58$<br>\n",
    "\n",
    "Mean Average Grade in four credit-hour:  $3.0775510204081638$<br>\n",
    "Median Average Grade four credit-hour:  $2.99$<br>\n",
    "\n",
    "Yes, it supports our hypothesis that students' grades are higher in one credit-hour course "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Another hypothesis one might want to test using this data set is whether or not students' grades are different based on the course *level* - lower-division (1000s and 2000s) versus upper-division (3000s and 4000s). Create side-by-side box-and-whisker plots to compare the average grades of lower-division computer science courses versus upper-division computer science courses.  Use the box-and-whisker plot conventions discussed in lecture, and be sure to include a legend and label your axes.\n",
    "\n",
    "Comment on the results. Does your figure suggest there is a difference in the distribution of average course grades, depending on whether a class is lower- or upper-division? If you noticed a difference between the two distributions, what is one cause that could explain this difference? Fully explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** One more hypothesis we might want to explore is whether or not there has actually been a large increase in Computer Science enrollments in recent years. There are 12 academic years of data, which means there are 24 distinct semesters (from Fall 2006 to Spring 2018). For each semester, compute the total number of students enrolled in Computer Science courses. Note that you will almost certainly be counting some students twice (or more!), but that's okay - this is still a good measure of the total demand for Computer Science classes. Use the total number of students enrolled at the end of the term as the number of students for each class.\n",
    "\n",
    "Make a plot of the total number of Computer Science students versus the semester, with the most recent semester (Spring 2018) on the right and most distant past (Fall 2006) on the left. Label your axes. For the semester axis (the x-axis), label with the actual semester as a character string, like \"Fall 2006\" or \"Spring 2007\", for example. You may want to look up how to rotate the x-tick labels in order to make the semester name labels fit nicely. Comment on the results and any interesting trends or patterns you notice in Computer Science enrollment numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F:** What is one way we could determine whether or not the Computer Science total enrollment is going up more than we should expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G:** Formulate another interesting question you could potentially answer using this data set. You do not need to actually answer it, but just frame the question clearly. What are some of the relevant column(s) in the data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
